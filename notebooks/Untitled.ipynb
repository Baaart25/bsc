{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61779af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import add_model_and_perturbation_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b70af3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'roberta'\n",
    "base_df = pd.read_table(f\"../exps/{directory}/base.tsv\", sep=\"\\t\", quoting=3)\n",
    "bow_df = pd.read_table(f\"../exps/{directory}/bow.tsv\", sep=\"\\t\", quoting=3)\n",
    "mask_df = pd.read_table(f\"../exps/{directory}/mask2.tsv\", sep=\"\\t\", quoting=3)\n",
    "#mask_target_df = pd.read_table(f\"../exps/{directory}/mask_target.tsv\", sep=\"\\t\", quoting=3)\n",
    "prev_next_two_df = pd.read_table(f\"../exps/{directory}/prev_next_two.tsv\", sep=\"\\t\", quoting=3)\n",
    "rand_df = pd.read_table(f\"../exps/{directory}/rand.tsv\", sep=\"\\t\", quoting=3)\n",
    "shift_df = pd.read_table(f\"../exps/{directory}/shift.tsv\", sep=\"\\t\", quoting=3)\n",
    "\n",
    "hung_base_df = pd.read_table(f\"../exps/{directory}/hung_base.tsv\", sep=\"\\t\", quoting=3)\n",
    "hung_bow_df = pd.read_table(f\"../exps/{directory}/hung_bow.tsv\", sep=\"\\t\", quoting=3)\n",
    "hung_mask_df = pd.read_table(f\"../exps/{directory}/hung_mask.tsv\", sep=\"\\t\", quoting=3)\n",
    "hung_prev_next_two_df = pd.read_table(f\"../exps/{directory}/hung_prev_next_two.tsv\", sep=\"\\t\", quoting=3)\n",
    "hung_rand_df = pd.read_table(f\"../exps/{directory}/hung_rand.tsv\", sep=\"\\t\", quoting=3)\n",
    "hung_shift_df = pd.read_table(f\"../exps/{directory}/hung_shift.tsv\", sep=\"\\t\", quoting=3)\n",
    "\n",
    "\n",
    "base_df = base_df.apply(add_model_and_perturbation_fields, axis=1)\n",
    "bow_df = bow_df.apply(add_model_and_perturbation_fields, axis=1)\n",
    "mask_df = mask_df.apply(add_model_and_perturbation_fields, axis=1)\n",
    "#mask_target_df = mask_target_df.apply(add_model_and_perturbation_fields, axis=1)\n",
    "prev_next_two_df = prev_next_two_df.apply(add_model_and_perturbation_fields, axis=1)\n",
    "rand_df = rand_df.apply(add_model_and_perturbation_fields, axis=1)\n",
    "shift_df = shift_df.apply(add_model_and_perturbation_fields, axis=1)\n",
    "\n",
    "hung_base_df = hung_base_df.apply(add_model_and_perturbation_fields, axis=1)\n",
    "hung_bow_df = hung_bow_df.apply(add_model_and_perturbation_fields, axis=1)\n",
    "hung_mask_df = hung_mask_df.apply(add_model_and_perturbation_fields, axis=1)\n",
    "hung_prev_next_two_df = hung_prev_next_two_df.apply(add_model_and_perturbation_fields, axis=1)\n",
    "hung_rand_df = hung_rand_df.apply(add_model_and_perturbation_fields, axis=1)\n",
    "hung_shift_df = hung_shift_df.apply(add_model_and_perturbation_fields, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "32cfc592",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = pd.concat([shift_df,\n",
    "                  bow_df,\n",
    "                  base_df,\n",
    "                  mask_df,\n",
    "                  #mask_target_df,\n",
    "                  prev_next_two_df,\n",
    "                  rand_df ], sort=True)\n",
    "exps['task'] = exps.apply (lambda row: row['dev_file'].split('/')[6], axis=1)\n",
    "exps['language'] = exps.apply (lambda row: row['dev_file'].split('/')[7], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "505669ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "hung_exps = pd.concat([hung_base_df,\n",
    "                       hung_bow_df,\n",
    "                       hung_mask_df,\n",
    "                       hung_prev_next_two_df,\n",
    "                       hung_rand_df,\n",
    "                       hung_shift_df], sort=True)\n",
    "hung_exps['task'] = hung_exps.apply (lambda row: row['dev_file'].split('/')[5], axis=1)\n",
    "hung_exps['language'] = hung_exps.apply (lambda row: row['dev_file'].split('/')[6], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e20f6c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = pd.concat([exps,\n",
    "                  hung_exps], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5f307204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>bow</th>\n",
       "      <th>commit_hash</th>\n",
       "      <th>dataset_class</th>\n",
       "      <th>dev_F_score</th>\n",
       "      <th>dev_acc</th>\n",
       "      <th>dev_acc_list</th>\n",
       "      <th>dev_file</th>\n",
       "      <th>dev_loss</th>\n",
       "      <th>dev_size</th>\n",
       "      <th>...</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>tokenize_n_chars</th>\n",
       "      <th>torch_random_seed</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_acc_list</th>\n",
       "      <th>train_base_model</th>\n",
       "      <th>train_file</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_size</th>\n",
       "      <th>use_character_tokenization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>144019f3483686cda974b27cc2a027f88027b19d</td>\n",
       "      <td>SentenceProberDataset</td>\n",
       "      <td>0.914947</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>[0.73, 0.805, 0.845, 0.855, 0.885, 0.875, 0.88...</td>\n",
       "      <td>/home1/morph/botond/morphology-probes/data/num...</td>\n",
       "      <td>[0.5490634739398956, 0.4755028039216995, 0.409...</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>306205096</td>\n",
       "      <td>[0.626, 0.7695, 0.8115, 0.851, 0.879, 0.9005, ...</td>\n",
       "      <td>[0.626, 0.7695, 0.8115, 0.851, 0.879, 0.9005, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>/home1/morph/botond/morphology-probes/data/num...</td>\n",
       "      <td>[0.6203865148127079, 0.5107036549597979, 0.443...</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>144019f3483686cda974b27cc2a027f88027b19d</td>\n",
       "      <td>SentenceProberDataset</td>\n",
       "      <td>0.929937</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>[0.79, 0.845, 0.87, 0.9, 0.905, 0.91, 0.92, 0....</td>\n",
       "      <td>/home1/morph/botond/morphology-probes/data/num...</td>\n",
       "      <td>[0.4164741635322571, 0.32688479125499725, 0.28...</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1978512079</td>\n",
       "      <td>[0.788, 0.8965, 0.924, 0.945, 0.962, 0.9645, 0...</td>\n",
       "      <td>[0.788, 0.8965, 0.924, 0.945, 0.962, 0.9645, 0...</td>\n",
       "      <td>False</td>\n",
       "      <td>/home1/morph/botond/morphology-probes/data/num...</td>\n",
       "      <td>[0.5287769977003336, 0.26820274628698826, 0.18...</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>144019f3483686cda974b27cc2a027f88027b19d</td>\n",
       "      <td>SentenceProberDataset</td>\n",
       "      <td>0.889989</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>[0.64, 0.64, 0.705, 0.76, 0.83, 0.825, 0.845, ...</td>\n",
       "      <td>/home1/morph/botond/morphology-probes/data/num...</td>\n",
       "      <td>[0.6308360397815704, 0.5806727707386017, 0.524...</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1415550840</td>\n",
       "      <td>[0.6605, 0.786, 0.833, 0.88, 0.914, 0.932, 0.9...</td>\n",
       "      <td>[0.6605, 0.786, 0.833, 0.88, 0.914, 0.932, 0.9...</td>\n",
       "      <td>False</td>\n",
       "      <td>/home1/morph/botond/morphology-probes/data/num...</td>\n",
       "      <td>[0.6457335129380226, 0.5053268503397703, 0.400...</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>144019f3483686cda974b27cc2a027f88027b19d</td>\n",
       "      <td>SentenceProberDataset</td>\n",
       "      <td>0.889989</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>[0.6, 0.665, 0.655, 0.745, 0.76, 0.78, 0.815, ...</td>\n",
       "      <td>/home1/morph/botond/morphology-probes/data/num...</td>\n",
       "      <td>[0.6583434641361237, 0.6113128662109375, 0.589...</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>266042150</td>\n",
       "      <td>[0.539, 0.6455, 0.6935, 0.7425, 0.8095, 0.837,...</td>\n",
       "      <td>[0.539, 0.6455, 0.6935, 0.7425, 0.8095, 0.837,...</td>\n",
       "      <td>False</td>\n",
       "      <td>/home1/morph/botond/morphology-probes/data/num...</td>\n",
       "      <td>[0.6836897060275078, 0.646312765777111, 0.6021...</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>144019f3483686cda974b27cc2a027f88027b19d</td>\n",
       "      <td>SentenceProberDataset</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>[0.57, 0.67, 0.72, 0.72, 0.74, 0.695, 0.725, 0...</td>\n",
       "      <td>/home1/morph/botond/morphology-probes/data/num...</td>\n",
       "      <td>[0.6695510745048523, 0.6224456429481506, 0.573...</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2046686768</td>\n",
       "      <td>[0.5715, 0.6725, 0.7305, 0.7485, 0.776, 0.82, ...</td>\n",
       "      <td>[0.5715, 0.6725, 0.7305, 0.7485, 0.776, 0.82, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>/home1/morph/botond/morphology-probes/data/num...</td>\n",
       "      <td>[0.6706883646547794, 0.6042707115411758, 0.542...</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>144019f3483686cda974b27cc2a027f88027b19d</td>\n",
       "      <td>SentenceProberDataset</td>\n",
       "      <td>0.859944</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>[0.605, 0.72, 0.765, 0.79, 0.8, 0.785, 0.82, 0...</td>\n",
       "      <td>/home1/morph/botond/hungarian_morph_probes/ten...</td>\n",
       "      <td>[0.6545200049877167, 0.611682802438736, 0.5703...</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>399946927</td>\n",
       "      <td>[0.5415, 0.6505, 0.7405, 0.7795, 0.8215, 0.847...</td>\n",
       "      <td>[0.5415, 0.6505, 0.7405, 0.7795, 0.8215, 0.847...</td>\n",
       "      <td>False</td>\n",
       "      <td>/home1/morph/botond/hungarian_morph_probes/ten...</td>\n",
       "      <td>[0.6857905723154545, 0.6316008567810059, 0.575...</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>144019f3483686cda974b27cc2a027f88027b19d</td>\n",
       "      <td>SentenceProberDataset</td>\n",
       "      <td>0.343746</td>\n",
       "      <td>0.356481</td>\n",
       "      <td>[0.07407407407407407, 0.12037037037037036, 0.1...</td>\n",
       "      <td>/home1/morph/botond/hungarian_morph_probes/cas...</td>\n",
       "      <td>[2.8736343383789062, 2.8498802185058594, 2.819...</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161252340</td>\n",
       "      <td>[0.056051587301587304, 0.13392857142857142, 0....</td>\n",
       "      <td>[0.056051587301587304, 0.13392857142857142, 0....</td>\n",
       "      <td>False</td>\n",
       "      <td>/home1/morph/botond/hungarian_morph_probes/cas...</td>\n",
       "      <td>[2.8893513679504395, 2.8242436349391937, 2.751...</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>144019f3483686cda974b27cc2a027f88027b19d</td>\n",
       "      <td>SentenceProberDataset</td>\n",
       "      <td>0.553610</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>[0.2916666666666667, 0.33796296296296297, 0.37...</td>\n",
       "      <td>/home1/morph/botond/hungarian_morph_probes/cas...</td>\n",
       "      <td>[2.7385445833206177, 2.5642852783203125, 2.376...</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1658461385</td>\n",
       "      <td>[0.19890873015873015, 0.4131944444444444, 0.50...</td>\n",
       "      <td>[0.19890873015873015, 0.4131944444444444, 0.50...</td>\n",
       "      <td>False</td>\n",
       "      <td>/home1/morph/botond/hungarian_morph_probes/cas...</td>\n",
       "      <td>[2.805478721857071, 2.521157920360565, 2.22216...</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>144019f3483686cda974b27cc2a027f88027b19d</td>\n",
       "      <td>SentenceProberDataset</td>\n",
       "      <td>0.748870</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[0.18981481481481483, 0.23148148148148148, 0.3...</td>\n",
       "      <td>/home1/morph/botond/hungarian_morph_probes/cas...</td>\n",
       "      <td>[2.804558515548706, 2.6568857431411743, 2.4802...</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>329015861</td>\n",
       "      <td>[0.11557539682539683, 0.26537698412698413, 0.3...</td>\n",
       "      <td>[0.11557539682539683, 0.26537698412698413, 0.3...</td>\n",
       "      <td>False</td>\n",
       "      <td>/home1/morph/botond/hungarian_morph_probes/cas...</td>\n",
       "      <td>[2.8611467629671097, 2.698787033557892, 2.4902...</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>144019f3483686cda974b27cc2a027f88027b19d</td>\n",
       "      <td>SentenceProberDataset</td>\n",
       "      <td>0.593964</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>[0.1574074074074074, 0.1712962962962963, 0.208...</td>\n",
       "      <td>/home1/morph/botond/hungarian_morph_probes/cas...</td>\n",
       "      <td>[2.8267061710357666, 2.74406898021698, 2.65287...</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>942404589</td>\n",
       "      <td>[0.09275793650793651, 0.19990079365079366, 0.2...</td>\n",
       "      <td>[0.09275793650793651, 0.19990079365079366, 0.2...</td>\n",
       "      <td>False</td>\n",
       "      <td>/home1/morph/botond/hungarian_morph_probes/cas...</td>\n",
       "      <td>[2.8627627938985825, 2.7385271936655045, 2.602...</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50358 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     batch_size    bow                               commit_hash  \\\n",
       "0           128  False  144019f3483686cda974b27cc2a027f88027b19d   \n",
       "1           128  False  144019f3483686cda974b27cc2a027f88027b19d   \n",
       "2           128  False  144019f3483686cda974b27cc2a027f88027b19d   \n",
       "3           128  False  144019f3483686cda974b27cc2a027f88027b19d   \n",
       "4           128  False  144019f3483686cda974b27cc2a027f88027b19d   \n",
       "..          ...    ...                                       ...   \n",
       "219         128  False  144019f3483686cda974b27cc2a027f88027b19d   \n",
       "220         128  False  144019f3483686cda974b27cc2a027f88027b19d   \n",
       "221         128  False  144019f3483686cda974b27cc2a027f88027b19d   \n",
       "222         128  False  144019f3483686cda974b27cc2a027f88027b19d   \n",
       "223         128  False  144019f3483686cda974b27cc2a027f88027b19d   \n",
       "\n",
       "             dataset_class  dev_F_score   dev_acc  \\\n",
       "0    SentenceProberDataset     0.914947  0.915000   \n",
       "1    SentenceProberDataset     0.929937  0.930000   \n",
       "2    SentenceProberDataset     0.889989  0.890000   \n",
       "3    SentenceProberDataset     0.889989  0.890000   \n",
       "4    SentenceProberDataset     0.818841  0.820000   \n",
       "..                     ...          ...       ...   \n",
       "219  SentenceProberDataset     0.859944  0.860000   \n",
       "220  SentenceProberDataset     0.343746  0.356481   \n",
       "221  SentenceProberDataset     0.553610  0.555556   \n",
       "222  SentenceProberDataset     0.748870  0.750000   \n",
       "223  SentenceProberDataset     0.593964  0.597222   \n",
       "\n",
       "                                          dev_acc_list  \\\n",
       "0    [0.73, 0.805, 0.845, 0.855, 0.885, 0.875, 0.88...   \n",
       "1    [0.79, 0.845, 0.87, 0.9, 0.905, 0.91, 0.92, 0....   \n",
       "2    [0.64, 0.64, 0.705, 0.76, 0.83, 0.825, 0.845, ...   \n",
       "3    [0.6, 0.665, 0.655, 0.745, 0.76, 0.78, 0.815, ...   \n",
       "4    [0.57, 0.67, 0.72, 0.72, 0.74, 0.695, 0.725, 0...   \n",
       "..                                                 ...   \n",
       "219  [0.605, 0.72, 0.765, 0.79, 0.8, 0.785, 0.82, 0...   \n",
       "220  [0.07407407407407407, 0.12037037037037036, 0.1...   \n",
       "221  [0.2916666666666667, 0.33796296296296297, 0.37...   \n",
       "222  [0.18981481481481483, 0.23148148148148148, 0.3...   \n",
       "223  [0.1574074074074074, 0.1712962962962963, 0.208...   \n",
       "\n",
       "                                              dev_file  \\\n",
       "0    /home1/morph/botond/morphology-probes/data/num...   \n",
       "1    /home1/morph/botond/morphology-probes/data/num...   \n",
       "2    /home1/morph/botond/morphology-probes/data/num...   \n",
       "3    /home1/morph/botond/morphology-probes/data/num...   \n",
       "4    /home1/morph/botond/morphology-probes/data/num...   \n",
       "..                                                 ...   \n",
       "219  /home1/morph/botond/hungarian_morph_probes/ten...   \n",
       "220  /home1/morph/botond/hungarian_morph_probes/cas...   \n",
       "221  /home1/morph/botond/hungarian_morph_probes/cas...   \n",
       "222  /home1/morph/botond/hungarian_morph_probes/cas...   \n",
       "223  /home1/morph/botond/hungarian_morph_probes/cas...   \n",
       "\n",
       "                                              dev_loss  dev_size  ...  \\\n",
       "0    [0.5490634739398956, 0.4755028039216995, 0.409...       200  ...   \n",
       "1    [0.4164741635322571, 0.32688479125499725, 0.28...       200  ...   \n",
       "2    [0.6308360397815704, 0.5806727707386017, 0.524...       200  ...   \n",
       "3    [0.6583434641361237, 0.6113128662109375, 0.589...       200  ...   \n",
       "4    [0.6695510745048523, 0.6224456429481506, 0.573...       200  ...   \n",
       "..                                                 ...       ...  ...   \n",
       "219  [0.6545200049877167, 0.611682802438736, 0.5703...       200  ...   \n",
       "220  [2.8736343383789062, 2.8498802185058594, 2.819...       216  ...   \n",
       "221  [2.7385445833206177, 2.5642852783203125, 2.376...       216  ...   \n",
       "222  [2.804558515548706, 2.6568857431411743, 2.4802...       216  ...   \n",
       "223  [2.8267061710357666, 2.74406898021698, 2.65287...       216  ...   \n",
       "\n",
       "     test_acc tokenize_n_chars  torch_random_seed  \\\n",
       "0    0.860000              0.0          306205096   \n",
       "1    0.965000              0.0         1978512079   \n",
       "2    0.920000              0.0         1415550840   \n",
       "3    0.885000              0.0          266042150   \n",
       "4    0.780000              0.0         2046686768   \n",
       "..        ...              ...                ...   \n",
       "219  0.845000              0.0          399946927   \n",
       "220  0.333333              0.0          161252340   \n",
       "221  0.509259              0.0         1658461385   \n",
       "222  0.712963              0.0          329015861   \n",
       "223  0.597222              0.0          942404589   \n",
       "\n",
       "                                             train_acc  \\\n",
       "0    [0.626, 0.7695, 0.8115, 0.851, 0.879, 0.9005, ...   \n",
       "1    [0.788, 0.8965, 0.924, 0.945, 0.962, 0.9645, 0...   \n",
       "2    [0.6605, 0.786, 0.833, 0.88, 0.914, 0.932, 0.9...   \n",
       "3    [0.539, 0.6455, 0.6935, 0.7425, 0.8095, 0.837,...   \n",
       "4    [0.5715, 0.6725, 0.7305, 0.7485, 0.776, 0.82, ...   \n",
       "..                                                 ...   \n",
       "219  [0.5415, 0.6505, 0.7405, 0.7795, 0.8215, 0.847...   \n",
       "220  [0.056051587301587304, 0.13392857142857142, 0....   \n",
       "221  [0.19890873015873015, 0.4131944444444444, 0.50...   \n",
       "222  [0.11557539682539683, 0.26537698412698413, 0.3...   \n",
       "223  [0.09275793650793651, 0.19990079365079366, 0.2...   \n",
       "\n",
       "                                        train_acc_list  train_base_model  \\\n",
       "0    [0.626, 0.7695, 0.8115, 0.851, 0.879, 0.9005, ...             False   \n",
       "1    [0.788, 0.8965, 0.924, 0.945, 0.962, 0.9645, 0...             False   \n",
       "2    [0.6605, 0.786, 0.833, 0.88, 0.914, 0.932, 0.9...             False   \n",
       "3    [0.539, 0.6455, 0.6935, 0.7425, 0.8095, 0.837,...             False   \n",
       "4    [0.5715, 0.6725, 0.7305, 0.7485, 0.776, 0.82, ...             False   \n",
       "..                                                 ...               ...   \n",
       "219  [0.5415, 0.6505, 0.7405, 0.7795, 0.8215, 0.847...             False   \n",
       "220  [0.056051587301587304, 0.13392857142857142, 0....             False   \n",
       "221  [0.19890873015873015, 0.4131944444444444, 0.50...             False   \n",
       "222  [0.11557539682539683, 0.26537698412698413, 0.3...             False   \n",
       "223  [0.09275793650793651, 0.19990079365079366, 0.2...             False   \n",
       "\n",
       "                                            train_file  \\\n",
       "0    /home1/morph/botond/morphology-probes/data/num...   \n",
       "1    /home1/morph/botond/morphology-probes/data/num...   \n",
       "2    /home1/morph/botond/morphology-probes/data/num...   \n",
       "3    /home1/morph/botond/morphology-probes/data/num...   \n",
       "4    /home1/morph/botond/morphology-probes/data/num...   \n",
       "..                                                 ...   \n",
       "219  /home1/morph/botond/hungarian_morph_probes/ten...   \n",
       "220  /home1/morph/botond/hungarian_morph_probes/cas...   \n",
       "221  /home1/morph/botond/hungarian_morph_probes/cas...   \n",
       "222  /home1/morph/botond/hungarian_morph_probes/cas...   \n",
       "223  /home1/morph/botond/hungarian_morph_probes/cas...   \n",
       "\n",
       "                                            train_loss train_size  \\\n",
       "0    [0.6203865148127079, 0.5107036549597979, 0.443...       2000   \n",
       "1    [0.5287769977003336, 0.26820274628698826, 0.18...       2000   \n",
       "2    [0.6457335129380226, 0.5053268503397703, 0.400...       2000   \n",
       "3    [0.6836897060275078, 0.646312765777111, 0.6021...       2000   \n",
       "4    [0.6706883646547794, 0.6042707115411758, 0.542...       2000   \n",
       "..                                                 ...        ...   \n",
       "219  [0.6857905723154545, 0.6316008567810059, 0.575...       2000   \n",
       "220  [2.8893513679504395, 2.8242436349391937, 2.751...       2016   \n",
       "221  [2.805478721857071, 2.521157920360565, 2.22216...       2016   \n",
       "222  [2.8611467629671097, 2.698787033557892, 2.4902...       2016   \n",
       "223  [2.8627627938985825, 2.7385271936655045, 2.602...       2016   \n",
       "\n",
       "    use_character_tokenization  \n",
       "0                        False  \n",
       "1                        False  \n",
       "2                        False  \n",
       "3                        False  \n",
       "4                        False  \n",
       "..                         ...  \n",
       "219                      False  \n",
       "220                      False  \n",
       "221                      False  \n",
       "222                      False  \n",
       "223                      False  \n",
       "\n",
       "[50358 rows x 59 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5e91813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps['model'] = exps['models'].apply(lambda models: list(models)[0])\n",
    "exps['perturbation'] = exps['perturbations'].apply(lambda models: list(models)[0])\n",
    "exps['probing_location'] = exps.apply (lambda row: row['subword_pooling'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "48d32adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = exps[exps.perturbation != 'mBERT-invalid-shift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8e039a47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exps = exps.drop([\"torch_random_seed\", \"dataset_class\", \"exception\",\n",
    "              \"train_base_model\", \"sort_data_by_length\", \"early_stopping_window\", \n",
    "              \"generate_empty_subdir\", \"epochs\", \"dropout\", \n",
    "              \"layer_pooling\", \"commit_hash\", \"lr_decay\", \"batch_size\", \"min_epochs\",\n",
    "              \"numpy_random_seed\", \"shift_target\", \"dev_size\", \"epochs_run\",\n",
    "              \"train_size\", \"save_min_epoch\", \"parameters\", \"dev_F_score\", \"test_F_score\",\n",
    "              \"early_stopping_monitor\", \"mask_positions\", \"mlp_layers\", \"mlp_nonlinearity\",\n",
    "              \"optimizer\", \"optimizer_kwargs\", \"overwrite_model\",\n",
    "              \"remove_diacritics\", \"shuffle_batches\", \"save_metric\", \n",
    "              \"use_character_tokenization\", \"dev_loss\", \"node\", \"running_time\", \"start_time\",\n",
    "              \"train_acc\", \"train_loss\", \"train_acc_list\", \"dev_acc_list\", \"gpu\", \"experiment_dir\", \n",
    "              \"train_file\", \"dev_file\", \"model\", \"subword_pooling\", \"model_name\", \n",
    "                  \"randomize_embedding_weights\", \"bow\", \"target_only\", \"tokenize_n_chars\"], axis=1)\n",
    "exps['model'] = exps.apply (lambda row: \"XLM-RoBERTa\", axis=1)\n",
    "\n",
    "#exps.to_csv('exps.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b0b19e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>dev_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>language</th>\n",
       "      <th>task</th>\n",
       "      <th>perturbation</th>\n",
       "      <th>probing_location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">XLM-RoBERTa</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Afrikaans</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">number_noun</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">B$_2$</th>\n",
       "      <th>first</th>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>0.965000</td>\n",
       "      <td>0.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">L$_2$</th>\n",
       "      <th>first</th>\n",
       "      <td>0.872857</td>\n",
       "      <td>0.862143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>0.966429</td>\n",
       "      <td>0.979286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R$_2$</th>\n",
       "      <th>first</th>\n",
       "      <td>0.881429</td>\n",
       "      <td>0.842143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Urdu</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">number_noun</th>\n",
       "      <th>permute</th>\n",
       "      <th>last</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.907143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev1</th>\n",
       "      <th>last</th>\n",
       "      <td>0.949286</td>\n",
       "      <td>0.874286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev2</th>\n",
       "      <th>last</th>\n",
       "      <td>0.887857</td>\n",
       "      <td>0.786429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">NaN</th>\n",
       "      <th>first</th>\n",
       "      <td>0.935714</td>\n",
       "      <td>0.902857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>0.976429</td>\n",
       "      <td>0.923571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5886 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  dev_acc  \\\n",
       "model       language  task        perturbation probing_location             \n",
       "XLM-RoBERTa Afrikaans number_noun B$_2$        first             0.855000   \n",
       "                                               last              0.965000   \n",
       "                                  L$_2$        first             0.872857   \n",
       "                                               last              0.966429   \n",
       "                                  R$_2$        first             0.881429   \n",
       "...                                                                   ...   \n",
       "            Urdu      number_noun permute      last              0.964286   \n",
       "                                  prev1        last              0.949286   \n",
       "                                  prev2        last              0.887857   \n",
       "                                  NaN          first             0.935714   \n",
       "                                               last              0.976429   \n",
       "\n",
       "                                                                 test_acc  \n",
       "model       language  task        perturbation probing_location            \n",
       "XLM-RoBERTa Afrikaans number_noun B$_2$        first             0.850000  \n",
       "                                               last              0.971429  \n",
       "                                  L$_2$        first             0.862143  \n",
       "                                               last              0.979286  \n",
       "                                  R$_2$        first             0.842143  \n",
       "...                                                                   ...  \n",
       "            Urdu      number_noun permute      last              0.907143  \n",
       "                                  prev1        last              0.874286  \n",
       "                                  prev2        last              0.786429  \n",
       "                                  NaN          first             0.902857  \n",
       "                                               last              0.923571  \n",
       "\n",
       "[5886 rows x 2 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps.groupby([\"model\",\"language\",\"task\", \"perturbation\",\"probing_location\"], dropna=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a96ffd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps.groupby([\"model\",\"language\",\"task\", \"perturbation\",\"probing_location\"], dropna=False).mean().to_csv('bert_exps.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b8409fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(\"exps.tsv\", sep=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cafd549",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dev_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6314/4136186223.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'language'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'task'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'perturbation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'probing_location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdev_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'dev_acc'"
     ]
    }
   ],
   "source": [
    "exps.groupby(['model', 'language', 'task', 'perturbation', 'probing_location']).mean().dev_acc.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc5a698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
